{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa1aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MERGED_CSV = Path(\"./data/b365_merged.csv\")\n",
    "RAW_DIR = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ab044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_8112/546588977.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged = pd.read_csv(MERGED_CSV, parse_dates=[\"Date\"], dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "merged = pd.read_csv(MERGED_CSV, parse_dates=[\"Date\"], dayfirst=True)\n",
    "merged = merged.sort_values([\"Date\",\"Div\",\"HomeTeam\",\"AwayTeam\"]).drop_duplicates(subset=[\"match_id\"], keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9ddf2e-014d-407a-9b5d-6159a36fbf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>Div</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HC</th>\n",
       "      <th>...</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Referee</th>\n",
       "      <th>__source_file</th>\n",
       "      <th>jn_date</th>\n",
       "      <th>jn_home</th>\n",
       "      <th>jn_away</th>\n",
       "      <th>jn_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ee520466726d91f</td>\n",
       "      <td>F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>lille</td>\n",
       "      <td>paris sg</td>\n",
       "      <td>2015-08-07|lille|paris sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92ff78b3164950d0</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Clattenburg</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>bournemouth</td>\n",
       "      <td>aston villa</td>\n",
       "      <td>2015-08-08|bournemouth|aston villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481f9a32684b2ed6</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>chelsea</td>\n",
       "      <td>swansea</td>\n",
       "      <td>2015-08-08|chelsea|swansea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5cd2e61c3f58beae</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Watford</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Jones</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>everton</td>\n",
       "      <td>watford</td>\n",
       "      <td>2015-08-08|everton|watford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0470cbc33f6e441</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L Mason</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>leicester</td>\n",
       "      <td>sunderland</td>\n",
       "      <td>2015-08-08|leicester|sunderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18236</th>\n",
       "      <td>e6e2c60f41c2acd4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SP1.csv</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>sevilla</td>\n",
       "      <td>villarreal</td>\n",
       "      <td>2025-09-23|sevilla|villarreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>ebe524fb650ef71e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>Vallecano</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SP1.csv</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>ath madrid</td>\n",
       "      <td>vallecano</td>\n",
       "      <td>2025-09-24|ath madrid|vallecano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>132df5db35d608fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Getafe</td>\n",
       "      <td>Alaves</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SP1.csv</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>getafe</td>\n",
       "      <td>alaves</td>\n",
       "      <td>2025-09-24|getafe|alaves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>bbcb70a8b61fc611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>Mallorca</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SP1.csv</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>sociedad</td>\n",
       "      <td>mallorca</td>\n",
       "      <td>2025-09-24|sociedad|mallorca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>1c79a37c4b4a76f4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18241 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               match_id  Div  Season        Date     HomeTeam     AwayTeam  \\\n",
       "0      3ee520466726d91f   F1     NaN  2015-08-07        Lille     Paris SG   \n",
       "1      92ff78b3164950d0   E0     NaN  2015-08-08  Bournemouth  Aston Villa   \n",
       "2      481f9a32684b2ed6   E0     NaN  2015-08-08      Chelsea      Swansea   \n",
       "3      5cd2e61c3f58beae   E0     NaN  2015-08-08      Everton      Watford   \n",
       "4      c0470cbc33f6e441   E0     NaN  2015-08-08    Leicester   Sunderland   \n",
       "...                 ...  ...     ...         ...          ...          ...   \n",
       "18236  e6e2c60f41c2acd4  NaN     NaN  2025-09-23      Sevilla   Villarreal   \n",
       "18237  ebe524fb650ef71e  NaN     NaN  2025-09-24   Ath Madrid    Vallecano   \n",
       "18238  132df5db35d608fd  NaN     NaN  2025-09-24       Getafe       Alaves   \n",
       "18239  bbcb70a8b61fc611  NaN     NaN  2025-09-24     Sociedad     Mallorca   \n",
       "18240  1c79a37c4b4a76f4  NaN     NaN         NaN          NaN          NaN   \n",
       "\n",
       "       FTHG  FTAG  FTR    HC  ...  HTHG  HTAG  HTR  Attendance        Referee  \\\n",
       "0       0.0   1.0    A   3.0  ...   0.0   0.0    D         NaN            NaN   \n",
       "1       0.0   1.0    A   6.0  ...   0.0   0.0    D         NaN  M Clattenburg   \n",
       "2       2.0   2.0    D   4.0  ...   2.0   1.0    H         NaN       M Oliver   \n",
       "3       2.0   2.0    D   8.0  ...   0.0   1.0    A         NaN        M Jones   \n",
       "4       4.0   2.0    H   6.0  ...   3.0   0.0    H         NaN        L Mason   \n",
       "...     ...   ...  ...   ...  ...   ...   ...  ...         ...            ...   \n",
       "18236   1.0   2.0    A   3.0  ...   0.0   1.0    A         NaN            NaN   \n",
       "18237   3.0   2.0    H   8.0  ...   1.0   1.0    D         NaN            NaN   \n",
       "18238   1.0   1.0    D   2.0  ...   0.0   0.0    D         NaN            NaN   \n",
       "18239   1.0   0.0    H  11.0  ...   0.0   0.0    D         NaN            NaN   \n",
       "18240   NaN   NaN  NaN   NaN  ...   NaN   NaN  NaN         NaN            NaN   \n",
       "\n",
       "       __source_file     jn_date      jn_home      jn_away  \\\n",
       "0        F1 (10).csv  2015-08-07        lille     paris sg   \n",
       "1        E0 (10).csv  2015-08-08  bournemouth  aston villa   \n",
       "2        E0 (10).csv  2015-08-08      chelsea      swansea   \n",
       "3        E0 (10).csv  2015-08-08      everton      watford   \n",
       "4        E0 (10).csv  2015-08-08    leicester   sunderland   \n",
       "...              ...         ...          ...          ...   \n",
       "18236        SP1.csv  2025-09-23      sevilla   villarreal   \n",
       "18237        SP1.csv  2025-09-24   ath madrid    vallecano   \n",
       "18238        SP1.csv  2025-09-24       getafe       alaves   \n",
       "18239        SP1.csv  2025-09-24     sociedad     mallorca   \n",
       "18240    F1 (10).csv         NaN          NaN          NaN   \n",
       "\n",
       "                                   jn_key  \n",
       "0               2015-08-07|lille|paris sg  \n",
       "1      2015-08-08|bournemouth|aston villa  \n",
       "2              2015-08-08|chelsea|swansea  \n",
       "3              2015-08-08|everton|watford  \n",
       "4         2015-08-08|leicester|sunderland  \n",
       "...                                   ...  \n",
       "18236       2025-09-23|sevilla|villarreal  \n",
       "18237     2025-09-24|ath madrid|vallecano  \n",
       "18238            2025-09-24|getafe|alaves  \n",
       "18239        2025-09-24|sociedad|mallorca  \n",
       "18240                                 NaN  \n",
       "\n",
       "[18241 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7be7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling rows: 18238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Div</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>total_corners</th>\n",
       "      <th>p_home</th>\n",
       "      <th>p_over25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>F1</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>E0</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>E0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>E0</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Watford</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>E0</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Div     HomeTeam     AwayTeam  total_corners  p_home  p_over25\n",
       "0  2015-08-07  F1        Lille     Paris SG            5.0     NaN       NaN\n",
       "1  2015-08-08  E0  Bournemouth  Aston Villa            9.0     NaN       NaN\n",
       "2  2015-08-08  E0      Chelsea      Swansea           12.0     NaN       NaN\n",
       "3  2015-08-08  E0      Everton      Watford           10.0     NaN       NaN\n",
       "4  2015-08-08  E0    Leicester   Sunderland            9.0     NaN       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = merged.copy()\n",
    "\n",
    "data[\"total_corners\"] = data[\"HC\"] + data[\"AC\"]\n",
    "\n",
    "def implied_probs(prices):\n",
    "    # convert to implied probabilities\n",
    "    inv = 1.0 / prices\n",
    "    s = inv.sum(axis=1)\n",
    "    return inv.div(s, axis=0)\n",
    "\n",
    "if {\"close_home\",\"close_draw\",\"close_away\"}.issubset(data.columns):\n",
    "    probs = implied_probs(data[[\"close_home\",\"close_draw\",\"close_away\"]])\n",
    "else:\n",
    "    probs = implied_probs(data[[\"pre_home\",\"pre_draw\",\"pre_away\"]])\n",
    "\n",
    "data[\"p_home\"] = probs.iloc[:,0]\n",
    "data[\"p_draw\"] = probs.iloc[:,1]\n",
    "data[\"p_away\"] = probs.iloc[:,2]\n",
    "\n",
    "if {\"close_over2_5\",\"close_under2_5\"}.issubset(data.columns):\n",
    "    inv_over = 1.0 / data[\"close_over2_5\"]\n",
    "    inv_under = 1.0 / data[\"close_under2_5\"]\n",
    "else:\n",
    "    inv_over = 1.0 / data[\"pre_over2_5\"]\n",
    "    inv_under = 1.0 / data[\"pre_under2_5\"]\n",
    "data[\"p_over25\"] = inv_over / (inv_over + inv_under)\n",
    "\n",
    "\n",
    "model_df = data.dropna(subset=[\"total_corners\",\"HomeTeam\",\"AwayTeam\"])\n",
    "model_df = model_df[model_df[\"total_corners\"] >= 0]\n",
    "\n",
    "print(\"Modeling rows:\", model_df.shape[0])\n",
    "model_df[[\"Date\",\"Div\",\"HomeTeam\",\"AwayTeam\",\"total_corners\",\"p_home\",\"p_over25\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aad0949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs: 17672 n_teams: 160 n_divs: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_feat = model_df.copy()\n",
    "df_feat = df_feat.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# pace ELO rolling window params\n",
    "win = 20\n",
    "minp = 5\n",
    "\n",
    "\n",
    "home_part = df_feat[[\"Date\",\"HomeTeam\",\"total_corners\"]].rename(columns={\"HomeTeam\":\"Team\"})\n",
    "away_part = df_feat[[\"Date\",\"AwayTeam\",\"total_corners\"]].rename(columns={\"AwayTeam\":\"Team\"})\n",
    "long_team = pd.concat([home_part, away_part], ignore_index=True)\n",
    "\n",
    "long_team = long_team.sort_values([\"Team\",\"Date\"])\n",
    "long_team[\"team_pace\"] = (\n",
    "    long_team\n",
    "    .groupby(\"Team\")[\"total_corners\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(win, min_periods=minp).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "home_pace = (long_team.rename(columns={\"Team\":\"HomeTeam\"})\n",
    "                        .set_index([\"HomeTeam\",\"Date\"])[\"team_pace\"])\n",
    "away_pace = (long_team.rename(columns={\"Team\":\"AwayTeam\"})\n",
    "                        .set_index([\"AwayTeam\",\"Date\"])[\"team_pace\"])\n",
    "\n",
    "df_feat = df_feat.set_index([\"HomeTeam\",\"Date\"])\n",
    "df_feat[\"pace_elo_home\"] = home_pace\n",
    "df_feat = df_feat.reset_index()\n",
    "\n",
    "df_feat = df_feat.set_index([\"AwayTeam\",\"Date\"])\n",
    "df_feat[\"pace_elo_away\"] = away_pace\n",
    "df_feat = df_feat.reset_index()\n",
    "\n",
    "df_feat = df_feat.dropna(subset=[\"pace_elo_home\", \"pace_elo_away\"]).reset_index(drop=True)\n",
    "\n",
    "# If early-season rows lack history, we can backfill with per-team mean, then global mean\n",
    "team_means = (\n",
    "    pd.concat([\n",
    "        long_team.groupby(\"Team\")[\"team_pace\"].mean().rename(\"m1\"),        # <-- removed min_count\n",
    "        long_team.groupby(\"Team\")[\"total_corners\"].mean().rename(\"m2\")\n",
    "    ], axis=1)\n",
    "    .assign(pace_fallback=lambda d: d[\"m1\"].fillna(d[\"m2\"]))\n",
    "    [\"pace_fallback\"]\n",
    ")\n",
    "\n",
    "def fill_team_pace(row, col_name, team_col):\n",
    "    val = row[col_name]\n",
    "    if pd.notna(val): \n",
    "        return val\n",
    "    tm = row[team_col]\n",
    "    if tm in team_means:\n",
    "        return team_means.loc[tm]\n",
    "    return long_team[\"total_corners\"].mean()\n",
    "\n",
    "df_feat[\"pace_elo_home\"] = df_feat.apply(lambda r: fill_team_pace(r, \"pace_elo_home\", \"HomeTeam\"), axis=1)\n",
    "df_feat[\"pace_elo_away\"] = df_feat.apply(lambda r: fill_team_pace(r, \"pace_elo_away\", \"AwayTeam\"), axis=1)\n",
    "\n",
    "\n",
    "def elo_z(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-8)\n",
    "\n",
    "df_feat[\"z_pace_diff\"] = elo_z(df_feat[\"pace_elo_home\"] - df_feat[\"pace_elo_away\"])\n",
    "df_feat[\"z_pace_sum\"]  = elo_z(df_feat[\"pace_elo_home\"] + df_feat[\"pace_elo_away\"])\n",
    "\n",
    "home_cats = pd.Categorical(df_feat[\"HomeTeam\"])\n",
    "away_cats = pd.Categorical(df_feat[\"AwayTeam\"], categories=home_cats.categories)\n",
    "home_idx = home_cats.codes\n",
    "away_idx = away_cats.codes\n",
    "n_teams  = len(home_cats.categories)\n",
    "div_cats = pd.Categorical(df_feat[\"Div\"])\n",
    "div_idx = div_cats.codes\n",
    "n_divs  = len(div_cats.categories)\n",
    "\n",
    "y = df_feat[\"total_corners\"].astype(int).values\n",
    "\n",
    "print(\"n_obs:\", len(y), \"n_teams:\", n_teams, \"n_divs:\", n_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7ada8-8875-4305-af53-ecf27434fa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma_team, sigma_div, intercept, home_adv, team_home_eff, team_away_eff, div_eff, beta_pace_diff, beta_pace_sum, rho]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/bayes-corners/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda3/envs/bayes-corners/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pm.Model() as nb_corners:\n",
    "    sigma_team = pm.HalfNormal(\"sigma_team\", 1.0)\n",
    "    sigma_div  = pm.HalfNormal(\"sigma_div\", 1.0)\n",
    "\n",
    "    intercept = pm.Normal(\"intercept\", 0.0, 1.5)\n",
    "    home_adv  = pm.Normal(\"home_adv\", 0.0, 0.5)\n",
    "\n",
    "    team_home_eff = pm.Normal(\"team_home_eff\", 0.0, sigma_team, shape=n_teams)\n",
    "    team_away_eff = pm.Normal(\"team_away_eff\", 0.0, sigma_team, shape=n_teams)\n",
    "\n",
    "    div_eff = pm.Normal(\"div_eff\", 0.0, sigma_div, shape=n_divs)\n",
    "\n",
    "    beta_pace_diff = pm.Normal(\"beta_pace_diff\", 0.0, 0.5)\n",
    "    beta_pace_sum  = pm.Normal(\"beta_pace_sum\", 0.0, 0.5)\n",
    "\n",
    "    # linear model from features\n",
    "    eta = (\n",
    "        intercept\n",
    "        + home_adv\n",
    "        + team_home_eff[home_idx]\n",
    "        + team_away_eff[away_idx]\n",
    "        + div_eff[div_idx]\n",
    "        + beta_pace_diff * df_feat[\"z_pace_diff\"].values\n",
    "        + beta_pace_sum  * df_feat[\"z_pace_sum\"].values\n",
    "    )\n",
    "\n",
    "    mu = pm.math.exp(eta)\n",
    "    rho = pm.Normal(\"rho\", mu=3.5, sigma=1.5)\n",
    "    alpha = pm.Deterministic(\"alpha\", pm.math.exp(rho))\n",
    "\n",
    "    y_obs = pm.NegativeBinomial(\"y_obs\", mu=mu, alpha=alpha, observed=y)\n",
    "\n",
    "    idata = pm.sample(4000, tune=4000, target_accept=0.95, chains=4, cores=4, random_seed=42)\n",
    "    idata = pm.sample_posterior_predictive(idata, extend_inferencedata=True)\n",
    "\n",
    "az.summary(idata, var_names=[\n",
    "    \"intercept\",\"home_adv\",\"sigma_team\",\"sigma_div\",\n",
    "    \"beta_pace_diff\",\"beta_pace_sum\",\"alpha\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014c117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce883f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pp_da = idata.posterior_predictive[\"y_obs\"]\n",
    "obs_dim = [d for d in y_pp_da.dims if d not in (\"chain\", \"draw\")][0]\n",
    "\n",
    "y_pp = (\n",
    "    y_pp_da\n",
    "    .stack(sample=(\"chain\", \"draw\"))\n",
    "    .transpose(\"sample\", obs_dim)\n",
    "    .values\n",
    ")\n",
    "\n",
    "y_pred_mean = y_pp.mean(axis=0)\n",
    "y_pred_var  = y_pp.var(axis=0, ddof=1)\n",
    "\n",
    "print(f\"OVERALL — mean(obs)={y.mean():.3f}  mean(pred.mean)={y_pred_mean.mean():.3f}\")\n",
    "print(f\"OVERALL — var(obs)={y.var(ddof=1):.3f}  mean(pred.var)={y_pred_var.mean():.3f}\")\n",
    "\n",
    "# quick overall PPC plot (unchanged)\n",
    "az.plot_ppc(idata, group=\"posterior\")\n",
    "plt.show()\n",
    "\n",
    "# 2) Helper: predictive interval coverage\n",
    "def coverage(y_pp_sub: np.ndarray, y_true_sub: np.ndarray, p: float) -> float:\n",
    "    lo = np.quantile(y_pp_sub, (1-p)/2, axis=0)\n",
    "    hi = np.quantile(y_pp_sub, 1-(1-p)/2, axis=0)\n",
    "    return float(np.mean((y_true_sub >= lo) & (y_true_sub <= hi)))\n",
    "\n",
    "# 3) Per-division summaries + plots\n",
    "if \"Div\" not in df_feat.columns:\n",
    "    df_feat = df_feat.copy()\n",
    "    df_feat[\"Div\"] = \"ALL\"\n",
    "\n",
    "divisions = pd.Categorical(df_feat[\"Div\"])\n",
    "div_names = list(divisions.categories)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Set this True to save PNGs instead of (or in addition to) showing\n",
    "SAVE_FIGS = False\n",
    "FIG_DPI = 110\n",
    "\n",
    "for div in div_names:\n",
    "    idx = np.flatnonzero(divisions == div)\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "\n",
    "    y_d = y[idx]\n",
    "    ypm_d = y_pred_mean[idx]\n",
    "    ypv_d = y_pred_var[idx]\n",
    "    ypp_d = y_pp[:, idx]   # (samples, n_div_obs)\n",
    "\n",
    "    # Summaries\n",
    "    obs_mean = y_d.mean()\n",
    "    pred_mean = ypm_d.mean()\n",
    "    obs_var = y_d.var(ddof=1)\n",
    "    pred_var = ypv_d.mean()\n",
    "    rmse_mean = float(np.sqrt(np.mean((y_d - ypm_d)**2)))\n",
    "\n",
    "    cov50 = coverage(ypp_d, y_d, 0.50)\n",
    "    cov80 = coverage(ypp_d, y_d, 0.80)\n",
    "    cov90 = coverage(ypp_d, y_d, 0.90)\n",
    "    cov95 = coverage(ypp_d, y_d, 0.95)\n",
    "\n",
    "    rows.append({\n",
    "        \"Division\": div,\n",
    "        \"n\": len(idx),\n",
    "        \"obs_mean\": obs_mean, \"pred_mean\": pred_mean,\n",
    "        \"obs_var\": obs_var,   \"pred_var\": pred_var,\n",
    "        \"RMSE_mean\": rmse_mean,\n",
    "        \"cov50\": cov50, \"cov80\": cov80, \"cov90\": cov90, \"cov95\": cov95\n",
    "    })\n",
    "\n",
    "    # --- Plots for this division ---\n",
    "    # A) Observed vs Predicted mean (per match)\n",
    "    plt.figure(figsize=(5.2, 4.2))\n",
    "    plt.scatter(y_d, ypm_d, alpha=0.35, s=14)\n",
    "    lo = min(y_d.min(), ypm_d.min())\n",
    "    hi = max(y_d.max(), ypm_d.max())\n",
    "    plt.plot([lo, hi], [lo, hi], lw=1)\n",
    "    plt.xlabel(\"Observed total corners\")\n",
    "    plt.ylabel(\"Predicted mean total corners\")\n",
    "    plt.title(f\"{div} — Obs vs Pred mean (n={len(idx)})\\n\"\n",
    "              f\"mean: {obs_mean:.2f}/{pred_mean:.2f} | var: {obs_var:.2f}/{pred_var:.2f}\")\n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(f\"ppc_mean_scatter_{div}.png\", dpi=FIG_DPI)\n",
    "    plt.show()\n",
    "\n",
    "    # B) Residuals histogram\n",
    "    residuals = y_d - ypm_d\n",
    "    plt.figure(figsize=(5.2, 4.0))\n",
    "    plt.hist(residuals, bins=20, alpha=0.8)\n",
    "    plt.axvline(0, color=\"k\", lw=1)\n",
    "    plt.xlabel(\"Residual = Observed − Predicted mean\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{div} — Residuals\")\n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(f\"ppc_residuals_{div}.png\", dpi=FIG_DPI)\n",
    "    plt.show()\n",
    "\n",
    "# 4) Display division summary table (sorted by sample size)\n",
    "div_summary = pd.DataFrame(rows).sort_values(\"n\", ascending=False)\n",
    "display(div_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac9ea8-c1e1-498c-ad26-c14fb234c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Observed vs Model: mean, variance, coverage, and grouped diagnostics ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Pull observed and posterior predictive draws\n",
    "# idata: PyMC v4 InferenceData with posterior_predictive[\"y_obs\"] (chain, draw, obs)\n",
    "y_true = np.asarray(df_feat[\"total_corners\"].astype(int).values)\n",
    "y_pp_da = idata.posterior_predictive[\"y_obs\"]\n",
    "\n",
    "# Convert to numpy with shape (samples, obs)\n",
    "y_pp = (y_pp_da\n",
    "        .stack(sample=(\"chain\",\"draw\"))\n",
    "        .transpose(\"sample\",\"y_obs_dim_0\")\n",
    "        .values)\n",
    "\n",
    "# Pointwise predictive mean & variance\n",
    "mu_hat = y_pp.mean(axis=0)           # (obs,)\n",
    "var_hat = y_pp.var(axis=0, ddof=1)   # (obs,)\n",
    "\n",
    "# 2) Overall diagnostics\n",
    "obs_mean = y_true.mean()\n",
    "pred_mean = mu_hat.mean()\n",
    "obs_var  = y_true.var(ddof=1)\n",
    "pred_var = var_hat.mean()\n",
    "\n",
    "rmse_mean = float(np.sqrt(np.mean((y_true - mu_hat)**2)))\n",
    "overdisp_ratio = float(np.var(y_true - mu_hat, ddof=1) / (pred_var + 1e-8))  # 1.0 is ideal-ish\n",
    "\n",
    "print(f\"Overall mean — observed: {obs_mean:.3f} | model: {pred_mean:.3f}\")\n",
    "print(f\"Overall var  — observed: {obs_var:.3f}  | model: {pred_var:.3f}\")\n",
    "print(f\"RMSE of mean predictions: {rmse_mean:.3f}\")\n",
    "print(f\"Residual overdispersion ratio (resid var / avg pred var): {overdisp_ratio:.3f}\")\n",
    "\n",
    "# 3) Coverage checks: does predictive interval contain observed y?\n",
    "def coverage(p):\n",
    "    lo = np.quantile(y_pp, (1-p)/2, axis=0)\n",
    "    hi = np.quantile(y_pp, 1-(1-p)/2, axis=0)\n",
    "    return float(np.mean((y_true >= lo) & (y_true <= hi)))\n",
    "\n",
    "for p in (0.50, 0.80, 0.90, 0.95):\n",
    "    print(f\"{int(p*100)}% predictive interval coverage: {coverage(p):.3f}\")\n",
    "\n",
    "# 4) Binned calibration by predicted mean (are we well-calibrated across difficulty?)\n",
    "bins = pd.qcut(mu_hat, 10, duplicates=\"drop\")\n",
    "calib = (pd.DataFrame({\n",
    "            \"bin\": bins,\n",
    "            \"y_true\": y_true,\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"var_hat\": var_hat\n",
    "        })\n",
    "        .groupby(\"bin\")\n",
    "        .agg(obs_mean=(\"y_true\",\"mean\"),\n",
    "             pred_mean=(\"mu_hat\",\"mean\"),\n",
    "             obs_var=(\"y_true\",\"var\"),\n",
    "             pred_var=(\"var_hat\",\"mean\"),\n",
    "             n=(\"y_true\",\"size\"))\n",
    "        .reset_index())\n",
    "\n",
    "print(\"\\nCalibration by predicted-mean decile:\")\n",
    "display(calib)\n",
    "\n",
    "# 5) Grouped diagnostics by league and by home team (customize as needed)\n",
    "def group_diag(df, group_col):\n",
    "    g = (pd.DataFrame({\n",
    "            group_col: df[group_col].values,\n",
    "            \"y_true\": y_true,\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"var_hat\": var_hat\n",
    "        })\n",
    "        .groupby(group_col)\n",
    "        .agg(obs_mean=(\"y_true\",\"mean\"),\n",
    "             pred_mean=(\"mu_hat\",\"mean\"),\n",
    "             obs_var=(\"y_true\",\"var\"),\n",
    "             pred_var=(\"var_hat\",\"mean\"),\n",
    "             n=(\"y_true\",\"size\"))\n",
    "        .sort_values(\"n\", ascending=False))\n",
    "    return g\n",
    "\n",
    "if \"Div\" in df_feat.columns:\n",
    "    print(\"\\nBy league/division:\")\n",
    "    display(group_diag(df_feat, \"Div\").head(15))\n",
    "\n",
    "print(\"\\nBy home team:\")\n",
    "display(group_diag(df_feat, \"HomeTeam\").head(20))\n",
    "\n",
    "# 6) Quick visuals (optional)\n",
    "# Mean calibration plot\n",
    "plt.scatter(calib[\"obs_mean\"], calib[\"pred_mean\"])\n",
    "plt.plot([calib[\"obs_mean\"].min(), calib[\"obs_mean\"].max()],\n",
    "         [calib[\"obs_mean\"].min(), calib[\"obs_mean\"].max()], lw=1)\n",
    "plt.xlabel(\"Observed mean (bin)\"); plt.ylabel(\"Predicted mean (bin)\")\n",
    "plt.title(\"Calibration: mean (by predicted-mean decile)\")\n",
    "plt.show()\n",
    "\n",
    "# Variance calibration plot\n",
    "plt.scatter(calib[\"obs_var\"], calib[\"pred_var\"])\n",
    "plt.plot([calib[\"obs_var\"].min(), calib[\"obs_var\"].max()],\n",
    "         [calib[\"obs_var\"].min(), calib[\"obs_var\"].max()], lw=1)\n",
    "plt.xlabel(\"Observed variance (bin)\"); plt.ylabel(\"Predicted variance (bin)\")\n",
    "plt.title(\"Calibration: variance (by predicted-mean decile)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880f19e-a758-4abe-b730-38767017d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output model artifacts\n",
    "\n",
    "\n",
    "train_feat = df_feat.copy()\n",
    "\n",
    "ARTIFACT_PREFIX = \"/corners_model\"  # <- CHANGE THIS\n",
    "Path(os.path.dirname(ARTIFACT_PREFIX)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_team_universe(df):\n",
    "    ht = df[\"HomeTeam\"].astype(str).unique()\n",
    "    at = df[\"AwayTeam\"].astype(str).unique()\n",
    "    return sorted(set(ht) | set(at))\n",
    "\n",
    "def make_div_universe(df):\n",
    "    if \"Div\" in df.columns:\n",
    "        return sorted([d for d in df[\"Div\"].dropna().astype(str).unique()])\n",
    "    return []\n",
    "\n",
    "team_universe = make_team_universe(train_feat)\n",
    "div_universe  = make_div_universe(train_feat)\n",
    "\n",
    "def safe_stats(series, default_mean=0.5, default_std=0.1):\n",
    "    if series is None:\n",
    "        return float(default_mean), float(default_std)\n",
    "    x = pd.to_numeric(series, errors=\"coerce\")\n",
    "    m = float(np.nanmean(x)) if np.isfinite(np.nanmean(x)) else default_mean\n",
    "    s = float(np.nanstd(x))  if np.isfinite(np.nanstd(x))  else default_std\n",
    "    s = max(s, 1e-6)\n",
    "    return m, s\n",
    "\n",
    "if \"p_home\" in train_feat.columns:\n",
    "    mean_p_home, std_p_home = safe_stats(train_feat[\"p_home\"])\n",
    "else:\n",
    "    mean_p_home, std_p_home = 0.5, 0.1\n",
    "    print(\"NOTE: 'p_home' not found; using defaults mean=0.5, std=0.1\")\n",
    "\n",
    "if \"p_over25\" in train_feat.columns:\n",
    "    mean_p_over25, std_p_over25 = safe_stats(train_feat[\"p_over25\"])\n",
    "else:\n",
    "    mean_p_over25, std_p_over25 = 0.5, 0.1\n",
    "    print(\"NOTE: 'p_over25' not found; using defaults mean=0.5, std=0.1\")\n",
    "\n",
    "zstats = {\n",
    "    \"mean_p_home\":   float(mean_p_home),\n",
    "    \"std_p_home\":    float(std_p_home),\n",
    "    \"mean_p_over25\": float(mean_p_over25),\n",
    "    \"std_p_over25\":  float(std_p_over25),\n",
    "}\n",
    "\n",
    "post = idata.posterior\n",
    "\n",
    "def flat(name):\n",
    "    if name not in post:\n",
    "        return None\n",
    "    arr = np.asarray(post[name])  # dims: (chain, draw, ...)\n",
    "    return arr.values.reshape(-1, *arr.shape[2:]) if hasattr(arr, \"values\") else arr.reshape(-1, *arr.shape[2:])\n",
    "\n",
    "draws = {}\n",
    "required_keys = [\"intercept\", \"home_adv\", \"team_home_eff\", \"team_away_eff\", \"alpha\"]\n",
    "optional_keys = [\"div_eff\", \"beta_homeprob\", \"beta_over25\"]\n",
    "\n",
    "for k in required_keys + optional_keys:\n",
    "    arr = flat(k)\n",
    "    if arr is not None:\n",
    "        # squeeze 0-d where appropriate\n",
    "        draws[k] = np.squeeze(arr)\n",
    "    elif k in required_keys:\n",
    "        raise KeyError(f\"Missing required posterior variable '{k}' in idata_tr.posterior\")\n",
    "\n",
    "\n",
    "np.savez_compressed(ARTIFACT_PREFIX + \"_draws.npz\", **draws)\n",
    "\n",
    "with open(ARTIFACT_PREFIX + \"_teams.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(list(team_universe), f, ensure_ascii=False)\n",
    "\n",
    "with open(ARTIFACT_PREFIX + \"_divs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(list(div_universe), f, ensure_ascii=False)\n",
    "\n",
    "with open(ARTIFACT_PREFIX + \"_zstats.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(zstats, f)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", ARTIFACT_PREFIX + \"_draws.npz\")\n",
    "print(\" -\", ARTIFACT_PREFIX + \"_teams.json\")\n",
    "print(\" -\", ARTIFACT_PREFIX + \"_divs.json\")\n",
    "print(\" -\", ARTIFACT_PREFIX + \"_zstats.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc867-8c3f-4812-b729-99975da40676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bayes-corners)",
   "language": "python",
   "name": "bayes-corners"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
