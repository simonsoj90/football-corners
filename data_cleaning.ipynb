{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658a9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, hashlib, unicodedata\n",
    "from pathlib import Path\n",
    "INPUT_DIR = Path(\"./data/raw\")     # place football-data CSVs here (e.g., I1.csv, E0.csv, etc.)\n",
    "OUTPUT_MERGED = Path(\"./data/b365_merged.csv\")  # final table\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b72a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_date_series(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "def make_match_id(row) -> str:\n",
    "    dt = row.get(\"Date\")\n",
    "    if not isinstance(dt, pd.Timestamp):\n",
    "        dt = pd.to_datetime(dt, errors=\"coerce\", dayfirst=True)\n",
    "    date_str = dt.strftime(\"%Y-%m-%d\") if isinstance(dt, pd.Timestamp) else \"\"\n",
    "    key = f\"{row.get('Div','')}|{date_str}|{row.get('HomeTeam','')}|{row.get('AwayTeam','')}\"\n",
    "    return hashlib.sha1(key.encode(\"utf-8\")).hexdigest()[:16]\n",
    "\n",
    "def norm_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    s = str(s)\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))\n",
    "    s = s.lower().replace(\"&\",\"and\").replace(\".\",\" \").replace(\"-\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def detect_b365_columns(columns):\n",
    "    cols = set(columns)\n",
    "    pre_1x2 = {k: k for k in [\"B365H\", \"B365D\", \"B365A\"] if k in cols}\n",
    "    close_1x2 = {k: k for k in [\"B365CH\", \"B365CD\", \"B365CA\"] if k in cols}\n",
    "    pre_ou = {}\n",
    "    if \"B365>2.5\" in cols: pre_ou[\"B365>2.5\"] = \"B365>2.5\"\n",
    "    if \"B365<2.5\" in cols: pre_ou[\"B365<2.5\"] = \"B365<2.5\"\n",
    "    close_ou = {}\n",
    "    if \"B365C>2.5\" in cols: close_ou[\"B365C>2.5\"] = \"B365C>2.5\"\n",
    "    if \"B365C<2.5\" in cols: close_ou[\"B365C<2.5\"] = \"B365C<2.5\"\n",
    "    pre_ah = {k: k for k in [\"B365AHH\", \"B365AHA\", \"B365AH\"] if k in cols}\n",
    "    close_ah = {k: k for k in [\"B365CAHH\", \"B365CAHA\", \"B365CAH\"] if k in cols}\n",
    "    return {\"pre_1x2\": pre_1x2, \"close_1x2\": close_1x2, \"pre_ou\": pre_ou, \"close_ou\": close_ou, \"pre_ah\": pre_ah, \"close_ah\": close_ah}\n",
    "\n",
    "def implied_probs_1x2(df):\n",
    "    cols_close = [\"close_home\",\"close_draw\",\"close_away\"]\n",
    "    cols_pre   = [\"pre_home\",\"pre_draw\",\"pre_away\"]\n",
    "    if set(cols_close).issubset(df.columns) and df[cols_close].notna().any(axis=None):\n",
    "        cols = cols_close\n",
    "    else:\n",
    "        cols = cols_pre\n",
    "    inv = 1.0 / df[cols]\n",
    "    inv_sum = inv.sum(axis=1)\n",
    "    probs = inv.div(inv_sum, axis=0).rename(columns={cols[0]:\"p_home\", cols[1]:\"p_draw\", cols[2]:\"p_away\"})\n",
    "    return probs\n",
    "\n",
    "def implied_prob_over25(df):\n",
    "    if {\"close_over2_5\",\"close_under2_5\"}.issubset(df.columns) and df[[\"close_over2_5\",\"close_under2_5\"]].notna().any(axis=None):\n",
    "        inv_over = 1.0 / df[\"close_over2_5\"]\n",
    "        inv_under = 1.0 / df[\"close_under2_5\"]\n",
    "    else:\n",
    "        inv_over = 1.0 / df.get(\"pre_over2_5\", pd.Series(index=df.index, dtype=float))\n",
    "        inv_under = 1.0 / df.get(\"pre_under2_5\", pd.Series(index=df.index, dtype=float))\n",
    "    return (inv_over / (inv_over + inv_under)).rename(\"p_over25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef703a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,\n",
       " ['D1 (1).csv',\n",
       "  'D1 (10).csv',\n",
       "  'D1 (2).csv',\n",
       "  'D1 (3).csv',\n",
       "  'D1 (4).csv',\n",
       "  'D1 (5).csv',\n",
       "  'D1 (6).csv',\n",
       "  'D1 (7).csv',\n",
       "  'D1 (8).csv',\n",
       "  'D1 (9).csv'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(INPUT_DIR.glob(\"*.csv\"))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No CSVs found in {INPUT_DIR}\")\n",
    "len(files), [f.name for f in files][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7040fc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "/var/folders/xy/fs1cvf415szgw9x79lyywp1h0000gn/T/ipykernel_70252/567111101.py:3: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57, 128, 57)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_frames = []\n",
    "odds_frames = []\n",
    "corners_frames = []\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, encoding=\"latin1\")\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(f, encoding=\"utf-8\", errors=\"ignore\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df[\"__source_file\"] = f.name\n",
    "\n",
    "    if not {\"Date\",\"HomeTeam\",\"AwayTeam\"}.issubset(df.columns):\n",
    "        continue\n",
    "\n",
    "    df[\"Date\"] = parse_date_series(df[\"Date\"])\n",
    "\n",
    "    for col in [\"Div\",\"FTHG\",\"FTAG\",\"FTR\",\"HTHG\",\"HTAG\",\"HTR\",\"Attendance\",\"Referee\",\"Season\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    m = df[[\"Div\",\"Date\",\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"FTR\",\"HTHG\",\"HTAG\",\"HTR\",\"Attendance\",\"Referee\",\"Season\",\"__source_file\"]].copy()\n",
    "    m[\"match_id\"] = m.apply(make_match_id, axis=1)\n",
    "    m[\"jn_date\"] = m[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    m[\"jn_home\"] = m[\"HomeTeam\"].apply(norm_team)\n",
    "    m[\"jn_away\"] = m[\"AwayTeam\"].apply(norm_team)\n",
    "    m[\"jn_key\"]  = m[\"jn_date\"] + \"|\" + m[\"jn_home\"] + \"|\" + m[\"jn_away\"]\n",
    "    matches_frames.append(m)\n",
    "\n",
    "    bcols = detect_b365_columns(df.columns)\n",
    "    if bcols[\"pre_1x2\"] or bcols[\"close_1x2\"]:\n",
    "        o = pd.DataFrame({\n",
    "            \"match_id\": m[\"match_id\"],\n",
    "            \"jn_key\": m[\"jn_key\"],\n",
    "            \"pre_home\": pd.to_numeric(df.get(\"B365H\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"pre_draw\": pd.to_numeric(df.get(\"B365D\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"pre_away\": pd.to_numeric(df.get(\"B365A\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_home\": pd.to_numeric(df.get(\"B365CH\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_draw\": pd.to_numeric(df.get(\"B365CD\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_away\": pd.to_numeric(df.get(\"B365CA\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "        })\n",
    "        odds_frames.append(o)\n",
    "\n",
    "    if bcols[\"pre_ou\"] or bcols[\"close_ou\"]:\n",
    "        ou = pd.DataFrame({\n",
    "            \"match_id\": m[\"match_id\"],\n",
    "            \"jn_key\": m[\"jn_key\"],\n",
    "            \"pre_over2_5\": pd.to_numeric(df.get(\"B365>2.5\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"pre_under2_5\": pd.to_numeric(df.get(\"B365<2.5\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_over2_5\": pd.to_numeric(df.get(\"B365C>2.5\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_under2_5\": pd.to_numeric(df.get(\"B365C<2.5\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "        })\n",
    "        odds_frames.append(ou)\n",
    "\n",
    "    if bcols[\"pre_ah\"] or bcols[\"close_ah\"]:\n",
    "        ah = pd.DataFrame({\n",
    "            \"match_id\": m[\"match_id\"],\n",
    "            \"jn_key\": m[\"jn_key\"],\n",
    "            \"pre_line_home\": pd.to_numeric(df.get(\"B365AH\",  pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_line_home\": pd.to_numeric(df.get(\"B365CAH\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"pre_home_ah\": pd.to_numeric(df.get(\"B365AHH\",  pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"pre_away_ah\": pd.to_numeric(df.get(\"B365AHA\",  pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_home_ah\": pd.to_numeric(df.get(\"B365CAHH\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "            \"close_away_ah\": pd.to_numeric(df.get(\"B365CAHA\", pd.Series(index=df.index, dtype=float)), errors=\"coerce\"),\n",
    "        })\n",
    "        odds_frames.append(ah)\n",
    "\n",
    "    cdf = df.copy()\n",
    "    if \"HC\" not in cdf.columns and \"HomeCorners\" in cdf.columns: cdf[\"HC\"] = cdf[\"HomeCorners\"]\n",
    "    if \"AC\" not in cdf.columns and \"AwayCorners\" in cdf.columns: cdf[\"AC\"] = cdf[\"AwayCorners\"]\n",
    "    if \"HC\" not in cdf.columns and \"HCA\" in cdf.columns: cdf[\"HC\"] = cdf[\"HCA\"]\n",
    "    if \"AC\" not in cdf.columns and \"ACA\" in cdf.columns: cdf[\"AC\"] = cdf[\"ACA\"]\n",
    "    if {\"HC\",\"AC\"}.issubset(cdf.columns):\n",
    "        corners = pd.DataFrame({\n",
    "            \"match_id\": m[\"match_id\"],\n",
    "            \"jn_key\": m[\"jn_key\"],\n",
    "            \"HC\": pd.to_numeric(cdf[\"HC\"], errors=\"coerce\"),\n",
    "            \"AC\": pd.to_numeric(cdf[\"AC\"], errors=\"coerce\"),\n",
    "        })\n",
    "        corners_frames.append(corners)\n",
    "\n",
    "len(matches_frames), len(odds_frames), len(corners_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7ad625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18241, 19), (18240, 18), (18241, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = pd.concat(matches_frames, ignore_index=True)\n",
    "matches = matches.sort_values([\"Date\",\"Div\",\"HomeTeam\",\"AwayTeam\"])\n",
    "matches = matches.drop_duplicates(subset=[\"match_id\"], keep=\"first\")\n",
    "\n",
    "odds = pd.concat(odds_frames, ignore_index=True) if odds_frames else pd.DataFrame(columns=[\"match_id\",\"jn_key\"])\n",
    "\n",
    "agg_map = {\n",
    "    \"pre_home\":\"first\",\"pre_draw\":\"first\",\"pre_away\":\"first\",\n",
    "    \"close_home\":\"first\",\"close_draw\":\"first\",\"close_away\":\"first\",\n",
    "    \"pre_over2_5\":\"first\",\"pre_under2_5\":\"first\",\"close_over2_5\":\"first\",\"close_under2_5\":\"first\",\n",
    "    \"pre_line_home\":\"first\",\"close_line_home\":\"first\",\n",
    "    \"pre_home_ah\":\"first\",\"pre_away_ah\":\"first\",\"close_home_ah\":\"first\",\"close_away_ah\":\"first\",\n",
    "}\n",
    "if not odds.empty:\n",
    "    odds = odds.groupby([\"match_id\",\"jn_key\"], as_index=False).agg(agg_map)\n",
    "\n",
    "corners = pd.concat(corners_frames, ignore_index=True) if corners_frames else pd.DataFrame(columns=[\"match_id\",\"jn_key\",\"HC\",\"AC\"])\n",
    "if not corners.empty:\n",
    "    corners = corners.drop_duplicates(subset=[\"jn_key\"], keep=\"first\")\n",
    "\n",
    "matches.shape, odds.shape, corners.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2006d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (18241, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>Div</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>total_corners</th>\n",
       "      <th>pre_home</th>\n",
       "      <th>pre_draw</th>\n",
       "      <th>pre_away</th>\n",
       "      <th>close_home</th>\n",
       "      <th>close_draw</th>\n",
       "      <th>close_away</th>\n",
       "      <th>pre_over2_5</th>\n",
       "      <th>pre_under2_5</th>\n",
       "      <th>close_over2_5</th>\n",
       "      <th>close_under2_5</th>\n",
       "      <th>pre_line_home</th>\n",
       "      <th>close_line_home</th>\n",
       "      <th>pre_home_ah</th>\n",
       "      <th>pre_away_ah</th>\n",
       "      <th>close_home_ah</th>\n",
       "      <th>close_away_ah</th>\n",
       "      <th>p_home</th>\n",
       "      <th>p_draw</th>\n",
       "      <th>p_away</th>\n",
       "      <th>p_over25</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Referee</th>\n",
       "      <th>__source_file</th>\n",
       "      <th>jn_date</th>\n",
       "      <th>jn_home</th>\n",
       "      <th>jn_away</th>\n",
       "      <th>jn_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ee520466726d91f</td>\n",
       "      <td>F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>lille</td>\n",
       "      <td>paris sg</td>\n",
       "      <td>2015-08-07|lille|paris sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92ff78b3164950d0</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Clattenburg</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>bournemouth</td>\n",
       "      <td>aston villa</td>\n",
       "      <td>2015-08-08|bournemouth|aston villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481f9a32684b2ed6</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>chelsea</td>\n",
       "      <td>swansea</td>\n",
       "      <td>2015-08-08|chelsea|swansea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5cd2e61c3f58beae</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Watford</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M Jones</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>everton</td>\n",
       "      <td>watford</td>\n",
       "      <td>2015-08-08|everton|watford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0470cbc33f6e441</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L Mason</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>leicester</td>\n",
       "      <td>sunderland</td>\n",
       "      <td>2015-08-08|leicester|sunderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4af88950f62e3288</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>man united</td>\n",
       "      <td>tottenham</td>\n",
       "      <td>2015-08-08|man united|tottenham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bf8179247a048d35</td>\n",
       "      <td>E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S Hooper</td>\n",
       "      <td>E0 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>norwich</td>\n",
       "      <td>crystal palace</td>\n",
       "      <td>2015-08-08|norwich|crystal palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a4a07af6ebe9f5e8</td>\n",
       "      <td>F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Bastia</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>bastia</td>\n",
       "      <td>rennes</td>\n",
       "      <td>2015-08-08|bastia|rennes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e055079d3c247b12</td>\n",
       "      <td>F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Caen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>marseille</td>\n",
       "      <td>caen</td>\n",
       "      <td>2015-08-08|marseille|caen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3a76c751cd357549</td>\n",
       "      <td>F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 (10).csv</td>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>montpellier</td>\n",
       "      <td>angers</td>\n",
       "      <td>2015-08-08|montpellier|angers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           match_id Div Season       Date     HomeTeam        AwayTeam  FTHG  \\\n",
       "0  3ee520466726d91f  F1    NaN 2015-08-07        Lille        Paris SG   0.0   \n",
       "1  92ff78b3164950d0  E0    NaN 2015-08-08  Bournemouth     Aston Villa   0.0   \n",
       "2  481f9a32684b2ed6  E0    NaN 2015-08-08      Chelsea         Swansea   2.0   \n",
       "3  5cd2e61c3f58beae  E0    NaN 2015-08-08      Everton         Watford   2.0   \n",
       "4  c0470cbc33f6e441  E0    NaN 2015-08-08    Leicester      Sunderland   4.0   \n",
       "5  4af88950f62e3288  E0    NaN 2015-08-08   Man United       Tottenham   1.0   \n",
       "6  bf8179247a048d35  E0    NaN 2015-08-08      Norwich  Crystal Palace   1.0   \n",
       "7  a4a07af6ebe9f5e8  F1    NaN 2015-08-08       Bastia          Rennes   2.0   \n",
       "8  e055079d3c247b12  F1    NaN 2015-08-08    Marseille            Caen   0.0   \n",
       "9  3a76c751cd357549  F1    NaN 2015-08-08  Montpellier          Angers   0.0   \n",
       "\n",
       "   FTAG FTR    HC   AC  total_corners  pre_home  pre_draw  pre_away  \\\n",
       "0   1.0   A   3.0  2.0            5.0      6.50       3.6      1.57   \n",
       "1   1.0   A   6.0  3.0            9.0      2.00       3.6      4.00   \n",
       "2   2.0   D   4.0  8.0           12.0      1.36       5.0     11.00   \n",
       "3   2.0   D   8.0  2.0           10.0      1.70       3.9      5.50   \n",
       "4   2.0   H   6.0  3.0            9.0      1.95       3.5      4.33   \n",
       "5   0.0   H   1.0  2.0            3.0      1.65       4.0      6.00   \n",
       "6   3.0   A   1.0  4.0            5.0      2.55       3.3      3.00   \n",
       "7   1.0   H   6.0  2.0            8.0      2.60       3.1      2.80   \n",
       "8   1.0   A  14.0  2.0           16.0      1.57       4.0      6.00   \n",
       "9   2.0   A   5.0  9.0           14.0      1.83       3.4      4.75   \n",
       "\n",
       "   close_home  close_draw  close_away  pre_over2_5  pre_under2_5  \\\n",
       "0         NaN         NaN         NaN          NaN           NaN   \n",
       "1         NaN         NaN         NaN          NaN           NaN   \n",
       "2         NaN         NaN         NaN          NaN           NaN   \n",
       "3         NaN         NaN         NaN          NaN           NaN   \n",
       "4         NaN         NaN         NaN          NaN           NaN   \n",
       "5         NaN         NaN         NaN          NaN           NaN   \n",
       "6         NaN         NaN         NaN          NaN           NaN   \n",
       "7         NaN         NaN         NaN          NaN           NaN   \n",
       "8         NaN         NaN         NaN          NaN           NaN   \n",
       "9         NaN         NaN         NaN          NaN           NaN   \n",
       "\n",
       "   close_over2_5  close_under2_5  pre_line_home  close_line_home  pre_home_ah  \\\n",
       "0            NaN             NaN            NaN              NaN          NaN   \n",
       "1            NaN             NaN            NaN              NaN          NaN   \n",
       "2            NaN             NaN            NaN              NaN          NaN   \n",
       "3            NaN             NaN            NaN              NaN          NaN   \n",
       "4            NaN             NaN            NaN              NaN          NaN   \n",
       "5            NaN             NaN            NaN              NaN          NaN   \n",
       "6            NaN             NaN            NaN              NaN          NaN   \n",
       "7            NaN             NaN            NaN              NaN          NaN   \n",
       "8            NaN             NaN            NaN              NaN          NaN   \n",
       "9            NaN             NaN            NaN              NaN          NaN   \n",
       "\n",
       "   pre_away_ah  close_home_ah  close_away_ah  p_home  p_draw  p_away  \\\n",
       "0          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "1          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "2          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "3          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "4          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "5          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "6          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "7          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "8          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "9          NaN            NaN            NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p_over25  HTHG  HTAG HTR  Attendance        Referee __source_file  \\\n",
       "0       NaN   0.0   0.0   D         NaN            NaN   F1 (10).csv   \n",
       "1       NaN   0.0   0.0   D         NaN  M Clattenburg   E0 (10).csv   \n",
       "2       NaN   2.0   1.0   H         NaN       M Oliver   E0 (10).csv   \n",
       "3       NaN   0.0   1.0   A         NaN        M Jones   E0 (10).csv   \n",
       "4       NaN   3.0   0.0   H         NaN        L Mason   E0 (10).csv   \n",
       "5       NaN   1.0   0.0   H         NaN         J Moss   E0 (10).csv   \n",
       "6       NaN   0.0   1.0   A         NaN       S Hooper   E0 (10).csv   \n",
       "7       NaN   0.0   1.0   A         NaN            NaN   F1 (10).csv   \n",
       "8       NaN   0.0   1.0   A         NaN            NaN   F1 (10).csv   \n",
       "9       NaN   0.0   1.0   A         NaN            NaN   F1 (10).csv   \n",
       "\n",
       "      jn_date      jn_home         jn_away                              jn_key  \n",
       "0  2015-08-07        lille        paris sg           2015-08-07|lille|paris sg  \n",
       "1  2015-08-08  bournemouth     aston villa  2015-08-08|bournemouth|aston villa  \n",
       "2  2015-08-08      chelsea         swansea          2015-08-08|chelsea|swansea  \n",
       "3  2015-08-08      everton         watford          2015-08-08|everton|watford  \n",
       "4  2015-08-08    leicester      sunderland     2015-08-08|leicester|sunderland  \n",
       "5  2015-08-08   man united       tottenham     2015-08-08|man united|tottenham  \n",
       "6  2015-08-08      norwich  crystal palace   2015-08-08|norwich|crystal palace  \n",
       "7  2015-08-08       bastia          rennes            2015-08-08|bastia|rennes  \n",
       "8  2015-08-08    marseille            caen           2015-08-08|marseille|caen  \n",
       "9  2015-08-08  montpellier          angers       2015-08-08|montpellier|angers  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = matches.merge(odds, on=[\"match_id\",\"jn_key\"], how=\"left\", suffixes=(\"\",\"\"))\n",
    "merged = merged.merge(corners[[\"jn_key\",\"HC\",\"AC\"]], on=\"jn_key\", how=\"left\")\n",
    "merged[\"total_corners\"] = merged[\"HC\"] + merged[\"AC\"]\n",
    "\n",
    "probs = implied_probs_1x2(merged)\n",
    "merged = pd.concat([merged, probs], axis=1)\n",
    "merged[\"p_over25\"] = implied_prob_over25(merged)\n",
    "\n",
    "cols_first = [\"match_id\",\"Div\",\"Season\",\"Date\",\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"FTR\",\"HC\",\"AC\",\"total_corners\"]\n",
    "odds_cols = [\"pre_home\",\"pre_draw\",\"pre_away\",\"close_home\",\"close_draw\",\"close_away\",\n",
    "             \"pre_over2_5\",\"pre_under2_5\",\"close_over2_5\",\"close_under2_5\",\n",
    "             \"pre_line_home\",\"close_line_home\",\"pre_home_ah\",\"pre_away_ah\",\"close_home_ah\",\"close_away_ah\"]\n",
    "prob_cols = [\"p_home\",\"p_draw\",\"p_away\",\"p_over25\"]\n",
    "meta_cols = [\"HTHG\",\"HTAG\",\"HTR\",\"Attendance\",\"Referee\",\"__source_file\",\"jn_date\",\"jn_home\",\"jn_away\",\"jn_key\"]\n",
    "final_cols = [c for c in cols_first + odds_cols + prob_cols + meta_cols if c in merged.columns]\n",
    "merged = merged[final_cols]\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "merged.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb65300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/b365_merged.csv\n"
     ]
    }
   ],
   "source": [
    "merged.to_csv(OUTPUT_MERGED, index=False)\n",
    "print(\"Saved:\", OUTPUT_MERGED)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bayes-corners)",
   "language": "python",
   "name": "bayes-corners"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
